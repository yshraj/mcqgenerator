{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries Required\n",
    "!pip install langchain-huggingface\n",
    "## For API Calls\n",
    "!pip install huggingface_hub\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install  bitsandbytes\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yashd\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# Load the Mistral-7B-Instruct-v0.2 model from Hugging Face API\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    huggingfacehub_api_token=HUGGINGFACE_TOKEN,\n",
    "    temperature=0.7,\n",
    "    max_new_tokens=1024  # Increased to allow full JSON output\n",
    ")\n",
    "\n",
    "# JSON response format\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    },\n",
    "    \"4\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\"\n",
    "        },\n",
    "        \"correct\": \"correct answer\"\n",
    "    }\n",
    "}\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "Text: {text}\n",
    "You are an expert MCQ generator. Based on the text above, create {number} multiple-choice questions \n",
    "for {subject} students at a difficulty level of {tone}. \n",
    "\n",
    "Your response **MUST be in valid JSON format**. Follow these strict rules:\n",
    "1. **DO NOT** include any explanations, markdown, or extra text‚Äî**return ONLY valid JSON**.\n",
    "2. **Ensure JSON syntax is correct**, with proper quotes and formatting.\n",
    "3. **Use unique, non-repetitive questions** strictly based on the text.\n",
    "4. **Options should be diverse and not misleading**.\n",
    "5. **Each question should have exactly four options (A, B, C, D)** and one correct answer.\n",
    "\n",
    "### **JSON RESPONSE FORMAT**\n",
    "```json\n",
    "{response_json}\"\"\"\n",
    "\n",
    "\n",
    "# Example input\n",
    "TEXT = \"\"\"Electromagnetic induction is the process of generating an electromotive force (EMF) or voltage across\n",
    "a conductor when exposed to a changing magnetic field. This principle was discovered by Michael Faraday in 1831\n",
    "and is the basis for electrical generators and transformers.\n",
    "\n",
    "According to Faraday‚Äôs Law, the magnitude of the induced EMF is directly proportional to the rate of change\n",
    "of magnetic flux through the conductor. Mathematically, it is expressed as:\n",
    "\n",
    "ùìî = -dŒ¶B/dt\n",
    "\n",
    "where ùìî is the induced EMF, and Œ¶B is the magnetic flux. The negative sign represents Lenz‚Äôs Law, which states\n",
    "that the induced current will always oppose the change in magnetic flux that caused it.\n",
    "\n",
    "There are two main types of electromagnetic induction: mutual induction and self-induction. Mutual induction\n",
    "occurs when a changing current in one coil induces an EMF in a nearby coil, as seen in transformers. Self-induction\n",
    "occurs when a changing current in a coil induces an EMF in the same coil due to its own changing magnetic field.\n",
    "\n",
    "This principle has widespread applications, including power generation, wireless charging, and credit card readers.\"\"\"\n",
    "\n",
    "# Create a LangChain prompt template\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "# Define the LangChain LLMChain\n",
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=False)\n",
    "\n",
    "# Parameters\n",
    "NUMBER = 5\n",
    "SUBJECT = \"Electromagnetic Induction\"\n",
    "TONE = \"easy\"\n",
    "\n",
    "# Generate MCQs\n",
    "response = quiz_chain.invoke({\n",
    "    \"text\": TEXT,\n",
    "    \"number\": NUMBER,\n",
    "    \"subject\": SUBJECT,\n",
    "    \"tone\": TONE,\n",
    "    \"response_json\": json.dumps(RESPONSE_JSON, indent=4)\n",
    "})\n",
    "\n",
    "# Extract the JSON part from response and parse it\n",
    "quiz_json_str = response[\"quiz\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": {\n",
      "        \"mcq\": \"Which scientist discovered the principle of electromagnetic induction?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Marconi\",\n",
      "            \"b\": \"Einstein\",\n",
      "            \"c\": \"Faraday\",\n",
      "            \"d\": \"Tesla\"\n",
      "        },\n",
      "        \"correct\": \"c\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"mcq\": \"What law states that the induced current will always oppose the change in magnetic flux?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Lenz's Law\",\n",
      "            \"b\": \"Faraday's Law\",\n",
      "            \"c\": \"Ohm's Law\",\n",
      "            \"d\": \"Coulomb's Law\"\n",
      "        },\n",
      "        \"correct\": \"a\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"mcq\": \"Which type of electromagnetic induction occurs when a changing current in one coil induces an EMF in a nearby coil?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"Mutual induction\",\n",
      "            \"b\": \"Self-induction\",\n",
      "            \"c\": \"Inductive coupling\",\n",
      "            \"d\": \"Capacitive coupling\"\n",
      "        },\n",
      "        \"correct\": \"a\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"mcq\": \"What is the mathematical expression for the induced EMF?\",\n",
      "        \"options\": {\n",
      "            \"a\": \"\\u03a6B = -d\\ud835\\udcd4/dt\",\n",
      "            \"b\": \"\\ud835\\udcd4 = -d\\u03a6B/dt\",\n",
      "            \"c\": \"\\u03a6B = d\\ud835\\udcd4/dt\",\n",
      "            \"d\": \"\\ud835\\udcd4 = d\\u03a6B/dt\"\n",
      "        },\n",
      "        \"correct\": \"b\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Original text containing the JSON\n",
    "text = quiz_json_str\n",
    "\n",
    "# Regular expression to extract JSON content\n",
    "json_string = re.search(r'```json(.*?)```', text, re.DOTALL).group(1).strip()\n",
    "\n",
    "# Convert the string to a JSON object\n",
    "data = json.loads(json_string)\n",
    "\n",
    "# Output the JSON data\n",
    "print(json.dumps(data, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
