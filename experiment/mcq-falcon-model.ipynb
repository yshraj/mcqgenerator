{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the model\n",
    "model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "# Load tokenizer & model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,use_auth_token=HUGGINGFACE_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Save model and tokenizer to Google Drive\n",
    "# save_path = \"../falcon_model\"\n",
    "# tokenizer.save_pretrained(save_path)\n",
    "# model.save_pretrained(save_path)\n",
    "\n",
    "# print(f\"Model saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text-generation pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    max_new_tokens=256  # Limit response length\n",
    ")\n",
    "\n",
    "# Wrap pipeline for LangChain\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON response format\n",
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# MCQ generation prompt\n",
    "TEMPLATE = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, create a quiz with {number} multiple-choice questions\n",
    "for {subject} students at a difficulty level of {tone}. Ensure questions follow the text accurately,\n",
    "are not repeated, and match the RESPONSE_JSON format below.\n",
    "\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Example input\n",
    "TEXT = \"\"\"Electromagnetic induction is the process of generating an electromotive force (EMF) or voltage across\n",
    "a conductor when exposed to a changing magnetic field. This principle was discovered by Michael Faraday in 1831\n",
    "and is the basis for electrical generators and transformers.\n",
    "\n",
    "According to Faraday‚Äôs Law, the magnitude of the induced EMF is directly proportional to the rate of change\n",
    "of magnetic flux through the conductor. Mathematically, it is expressed as:\n",
    "\n",
    "ùìî = -dŒ¶B/dt\n",
    "\n",
    "where ùìî is the induced EMF, and Œ¶B is the magnetic flux. The negative sign represents Lenz‚Äôs Law, which states\n",
    "that the induced current will always oppose the change in magnetic flux that caused it.\n",
    "\n",
    "There are two main types of electromagnetic induction: mutual induction and self-induction. Mutual induction\n",
    "occurs when a changing current in one coil induces an EMF in a nearby coil, as seen in transformers. Self-induction\n",
    "occurs when a changing current in a coil induces an EMF in the same coil due to its own changing magnetic field.\n",
    "\n",
    "This principle has widespread applications, including power generation, wireless charging, and credit card readers.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")\n",
    "\n",
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n",
    "\n",
    "NUMBER = 5\n",
    "SUBJECT = \"Electromagnetic Induction\"\n",
    "TONE = \"simple\"\n",
    "\n",
    "# Generate MCQs\n",
    "response = quiz_chain({\n",
    "    \"text\": TEXT,\n",
    "    \"number\": NUMBER,\n",
    "    \"subject\": SUBJECT,\n",
    "    \"tone\": TONE,\n",
    "    \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "})\n",
    "\n",
    "# Print results\n",
    "print(\"Generated MCQs:\\n\", response[\"quiz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
